{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Perovskite Dataset\n",
    "==============================\n",
    "\n",
    "**Author:** Panayotis Manganaris\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurization\n",
    "import cmcl\n",
    "from cmcl import Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading stored targets and reference material\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = pd.read_csv(\"./mannodi_data.csv\").set_index([\"index\", \"Formula\", \"sim_cell\"])\n",
    "lookup = pd.read_csv(\"./constituent_properties.csv\").set_index(\"Formula\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cmcl provides an \"ft\" (feature) pandas DataFrame accessor. This\n",
    "accessor exposes batch feature extraction tools. The function ft.comp\n",
    "extracts composition vectors from the formula string in a dataframe\n",
    "(or dataframe index).\n",
    "\n",
    "The abx function of the collect accessor is a convenience function for\n",
    "grouping the resulting composition constituents by site membership\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = my.ft.comp() # compute numerical compostion vectors from strings\n",
    "mc = mc.collect.abx() # convenient site groupings for perovskites data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this can be used with the logif tool in categories to quickly\n",
    "categorize records by their mix status. that status is assigned to the\n",
    "index of the respective tables for further reference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixlog = mc.groupby(level=0, axis=1).count()\n",
    "mix = mixlog.pipe(Categories.logif, condition=lambda x: x>1, default=\"pure\", catstring=\"and\")\n",
    "mc = mc.assign(mix=mix).set_index(\"mix\", append=True)\n",
    "my = my.assign(mix=mix).set_index(\"mix\", append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derive<sub>from</sub> function can be used to compute the site-averaged\n",
    "properties of each record.\n",
    "\n",
    "It performs a three-way N-to-N table join, performs a weighted\n",
    "averaging of any resulting redundant entries, and finally reshapes the\n",
    "results to be consistent with the outermost indices of the accessed\n",
    "data frame. Hence to obtain the site averaged properties, the\n",
    "composition table column labels must be grouped first, as above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = mc.ft.derive_from(lookup, \"element\", \"Formula\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target space\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main target of interest in this exercise is the Perovskite band\n",
    "gap.\n",
    "\n",
    "A number of properties including band gap and dielectric constant have\n",
    "been collected from DFT computations using the PBE functional.\n",
    "\n",
    "These properties are targets for modeling. Ideally, an empirical model\n",
    "can be found that fits to the underlying quantum mechanics, thereby\n",
    "acting as a surrogate for the DFT function in an active learning\n",
    "strategy which can quickly recommend compositions as high-performing\n",
    "candidates for DFT calculation.\n",
    "\n",
    "The target space is briefly summarized in both uni-variate and bi-variate views\n",
    "\n",
    "Note: there are an additional two \"SLME\" properties in the dataset\n",
    "(not shown here) that have extremely strong relations with band\n",
    "gap. They are computed using the band gap and a reference\n",
    "solar-absorption spectra. cmcl does not yet have a utility for\n",
    "computing them, so they are included in the sample data for reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "p = sns.pairplot(my.filter(regex=r\"PBE|dielc\").drop(\"PBE_dbg_eV\", axis=1).assign(mix=mix), hue='mix')\n",
    "p.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature space\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition Distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "composition vectors are a set of primary descriptors for the\n",
    "Perovskites being examined &#x2013; most other meaningful features are at\n",
    "least partially derived from them. Another primary descriptor is the\n",
    "crystal structure. For now, it is understood that the 496 records\n",
    "being examined are all cubic perovskites (within a tolerance). They\n",
    "differ firstly in composition and secondly in alloy character. Alloy\n",
    "character as a metric is completely encapsulated in the composition\n",
    "vectors, but nonetheless represents an important consideration in\n",
    "ensuring the model's generality.\n",
    "\n",
    "It will be a goal of modeling to create regressions that will be able\n",
    "to extrapolate targets between the existing alloy character classes.\n",
    "(AandBandX-site alloys).\n",
    "\n",
    "Here, uni-variate distributions over finite bounds on composition\n",
    "ratios are explored with respect to the alloy class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmc = pd.melt(\n",
    "    pd.DataFrame(\n",
    "        mc.fillna(0).pipe(Normalizer(norm=\"l1\").fit_transform), #normalizing the data by each vector's manhattan length gives proportional quantities\n",
    "        columns=mc.columns,\n",
    "        index=mc.index).assign(mix=mix),\n",
    "    id_vars=\"mix\").replace(0, np.NaN).dropna() # eliminate the \"zeros\" (missing values) to focus on the meaningful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"poster\"):\n",
    "    p = sns.catplot(x=\"value\", col=\"element\", data=nmc, col_wrap=5, kind=\"count\", hue=\"mix\",\n",
    "                    col_order=[\"Ba\", \"Ge\", \"Cl\", \"Br\", \"I\", \"Sn\", \"Pb\", \"Cs\", \"FA\", \"MA\", \"Sr\", \"Ca\", \"Rb\", \"K\"])\n",
    "    (p.set_xticklabels(rotation=90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site-Averaged Properties Distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxr = pd.IndexSlice\n",
    "some_axes = mp.loc[:, dxr[:, mp.columns.get_level_values(1)[0:4]]] #change these level value slices to focus on different site axes or remove slicing to see all\n",
    "smp = pd.melt(\n",
    "    pd.DataFrame(\n",
    "        some_axes.pipe(StandardScaler().fit_transform), #Z transform scales dimensions so they are comparable\n",
    "        columns=some_axes.columns,\n",
    "        index=some_axes.index).assign(mix=mix),\n",
    "    id_vars=\"mix\").replace(0, np.NaN).dropna() # eliminate \"zeros\" (missing values) to focus on the meaningful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\"):\n",
    "    p = sns.displot(x=\"value\", col=smp.iloc[:,2], row=\"site\", data=smp, kind=\"hist\", hue=\"mix\", multiple='stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-variate relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is unlikely that any of the targets is full explained by a single\n",
    "composition or composition derived axis. But there are probably\n",
    "relations.\n",
    "\n",
    "A Pearson correlation map will be produced to check for strong\n",
    "relations.\n",
    "\n",
    "Then, if any exist, they will be plotted in detail.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### targets vs composition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_v_targets = pd.concat([my, mc], axis=1).select_dtypes(np.number).fillna(0)\n",
    "pearson = pd.DataFrame(np.corrcoef(mc_v_targets, rowvar=False),\n",
    "                       columns=mc_v_targets.columns,\n",
    "                       index=mc_v_targets.columns)\n",
    "subset = pearson.filter(regex=r\"PBE|dielc|SLME\", axis=0).filter(regex=r\"^(?!PBE|HSE|SLME|dielc|PV_FOM)\")\n",
    "#first filter picks targets, second selects bases\n",
    "p = sns.heatmap(subset, vmax=1.0, vmin=-1.0, cmap=\"seismic\")\n",
    "p.set_xticklabels(p.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "p.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### targets vs site-averaged properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_v_targets = pd.concat([my, mp], axis=1).select_dtypes(np.number).fillna(0)\n",
    "pearson = pd.DataFrame(np.corrcoef(mp_v_targets, rowvar=False),\n",
    "                       columns=mp_v_targets.columns,\n",
    "                       index=mp_v_targets.columns)\n",
    "subset = pearson.filter(regex=r\"PBE|dielc|SLME\", axis=0).filter(regex=r\"^(?!PBE|HSE|SLME|dielc|PV_FOM)\")\n",
    "#first filter picks targets, second selects bases\n",
    "p = sns.heatmap(subset, vmax=1.0, vmin=-1.0, cmap=\"seismic\")\n",
    "p.set_xticklabels(p.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "p.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlated axes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unsurprisingly no simple explanations exist. to get a better idea of\n",
    "what structures statistical models might be able to find in the\n",
    "complete dataset, the structure and effects of many variables at a\n",
    "time must be inspected.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mrsicms)",
   "language": "python",
   "name": "mrsicms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
