{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Using neural networks to recognize clothing items from their images*\n",
    " \n",
    " \n",
    "In this tutorial, we will learn how to use the [Keras](https://keras.io/) and [Tensorflow](https://www.tensorflow.org/) libraries to create a neural network that classifies various images from the [Fashion MNIST Dataset](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) into different types of clothing items. \n",
    "\n",
    "This tutorial uses Python, some familiarity with programming would be beneficial but is not required. Run each code cell in order by hitting \"Shift + Enter\", or clicking the \"Run\" button in the menu bar above this notebook. Feel free to modify the code to familiarize yourself with how the code works.\n",
    "\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "1. Import libraries\n",
    "2. Getting data\n",
    "3. Explore and preprocess the data\n",
    "4. Build and train a neural network to model the data\n",
    "5. Evaluate model accuracy\n",
    "6. Make some predictions\n",
    "7. Visualize results\n",
    "\n",
    "**Get started:** Hit \"Shift-Enter\" on the code cells to run! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Import libraries\n",
    "\n",
    "We first import the relevant libraries. This includes Tensorflow and [Keras](https://www.tensorflow.org/guide/keras) to build and train neural networks, [Numpy](https://docs.scipy.org/doc/numpy-1.15.1/user/index.html) to process the data, and pyplot from [Matplotlib](https://matplotlib.org/) for plotting. We will also use the [Gzip](https://docs.python.org/3/library/gzip.html) and os libraries to handle zipped (compressed) files and to place the extracted data in the correct directories. The [subprocess](https://docs.python.org/2/library/subprocess.html) library allows us to call Unix shell commands from a Python script, and will be used to get the data from an online server directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from subprocess import call\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below sets the random seed to ensure consistent results every time the notebook is run, an important step in reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Getting data\n",
    "\n",
    "\n",
    "The Fashion MNIST database contains 70,000 grayscale images of 10 different categories of clothing items. The images show individual articles of clothing at low resolution (28 by 28 pixels). We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images.\n",
    "\n",
    "For more information on the dataset, click [here](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/).\n",
    "\n",
    "Testing and training datasets are located as compressed in gzip files [here](https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz). To download the data from this location, we define two helper functions. The first is `load_data()`, which uses the subprocess library to call the `wget` Unix command that downloads data from an online location to a specified directory on our system. This directory is specificed using the os library. The second function `extract_data()`, takes the data from the gzip and formats it into a (60,000 x 28 x 28 x 1) array of 8 byte, unsigned integers. In this notation, 60,000 is the number of training images, 28 is the height and width of each image (in pixels), and 1 is the number of \"channels\" in the image. For a grayscale image, the number of \"channels\" is 1, a colored image would have 3 \"channels\" (RGB).\n",
    "\n",
    "Labels for each image are defined as a number from 0 to 9, each corresponding to a class of clothing items, these class labels are defined in a list.\n",
    "\n",
    "Label | Class\n",
    "--- | --- \n",
    "0 | Tshirt/top\n",
    "1 | Trouser\n",
    "2 | Pullover\n",
    "3 | Dress\n",
    "4 | Coat\n",
    "5 | Sandal\n",
    "6 | Shirt\n",
    "7 | Sneaker\n",
    "8 | Bag\n",
    "9 | Ankle Boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_data, head_size, data_size): # This function loads and parses the data\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(head_size)\n",
    "        buf = bytestream.read(data_size * num_data)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8)\n",
    "    return data\n",
    "\n",
    "def load_data():\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz  -o \" \\\n",
    "         + os.getcwd() + \"t10k-images-idx3-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz -o \" \\\n",
    "         + os.getcwd() + \"train-images-idx3-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz -o \" \\\n",
    "         + os.getcwd() + \"train-labels-idx1-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz -o \" \\\n",
    "         + os.getcwd() + \"t10k-labels-idx1-ubyte.gz\", shell=True)\n",
    "\n",
    "    trainImages = extract_data(os.getcwd() + '/train-images-idx3-ubyte.gz', 60000, 16, 28*28)\n",
    "    testImages = extract_data(os.getcwd()  + '/t10k-images-idx3-ubyte.gz', 10000, 16, 28*28)\n",
    "    \n",
    "    trainLabels = extract_data(os.getcwd() + '/train-labels-idx1-ubyte.gz', 60000, 8, 1)\n",
    "    testLabels = extract_data(os.getcwd()  + '/t10k-labels-idx1-ubyte.gz', 10000, 8, 1)\n",
    "    \n",
    "    trainImages = trainImages.reshape((60000, 28, 28, 1))\n",
    "    testImages = testImages.reshape((10000, 28, 28, 1))\n",
    "    \n",
    "    trainLabels = trainLabels.reshape((60000, 1))\n",
    "    testLabels = testLabels.reshape((10000, 1))\n",
    "    \n",
    "    return trainImages, testImages, trainLabels, testLabels\n",
    "\n",
    "\n",
    "trainImages, testImages, trainLabels, testLabels = load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', \n",
    "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # Label Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Explore and preprocess the data\n",
    "\n",
    "To ensure that data was loaded correctly, we will now look at a sample image from the training set.\n",
    "\n",
    "- You can modify the variable **\"index\"** in the following code to get any image in the training set\n",
    "- You can print the shapes of all arrays being used to check whether the data was loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "index = 0 #index runs from 0 to 59999\n",
    "plt.imshow(trainImages[index], cmap='gray') # By altering 'index' you will see another of the pictures imported\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "\n",
    "print(\"Train Images Array shape:\", trainImages.shape)\n",
    "print(\"Train Labels Array shape:\", trainLabels.shape)\n",
    "print(\"Test Images Array shape:\", testImages.shape)\n",
    "print(\"Test Labels Array shape:\", testLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now scale the data to range between 0 and 1 before feeding it to the neural network model. It's important that the training set and the testing set are preprocessed in the same way and we thus divide the training and testing data by 255 (the maximum value that can be possibly achieved). Click [here](https://en.wikipedia.org/wiki/Feature_scaling) to learn about other types for feature (input) scaling.\n",
    "\n",
    "After this, we display the first 25 images from the dataset to visualize the variety of images in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = trainImages/255.0\n",
    "testImages = testImages/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainImages[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[int(trainLabels[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Build and train neural network to model the data\n",
    "\n",
    "Building the neural network requires configuring the layers of the model, then compiling the model. We use the Sequential class to quickly add layers to our model.\n",
    "\n",
    "In this instance, we will be using `Conv2D` and `Pool` layers to build our model. `Conv2D` layers are layers that represent convolution operations on an input array. These convolution operations use \"filters\" to learn the features in the images. These \"filters\" are small matrices (often 2x2 or 3x3) whose entries are learnt by the model during training. These values are optimized such that the network learns image features across multiple `Conv2D` layers. `Pool` layers \"pool\" or gather information from a set of pixels into one pixel. To learn more about `Conv2D` layers and the underlying operations, click [here](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks).\n",
    "\n",
    "After multiple convolution and pooling operations, we will use a `Flatten` layer to flatten the image into a long vector of numbers. Finally, we will use a `Dense` layer to predict the output of the network, which will be a set of 10 numbers that each define the probability of the current image being of that image class.\n",
    "\n",
    "The convolutional layers use a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks) (Rectified Linear Unit) [activation function](https://en.wikipedia.org/wiki/Activation_function), which can be seen as a \"ramp\" function in which only the positive part of the input passes through.\n",
    "\n",
    "The output layer layer uses a **SoftMax** (Normalized Exponential Function) activation, in which inputs are mapped into real values such that each value is between 0 and 1 and the sum of all values equals one. This helps us interpret these outputs as probabilities, and further distill them as predicted classes\n",
    "\n",
    "Click [here](https://towardsdatascience.com/secret-sauce-behind-the-beauty-of-deep-learning-beginners-guide-to-activation-functions-a8e23a57d046) to see and visualize the equations describing these activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(28, 28, 1)))\n",
    "model.add(layers.Conv2D(8, 3, activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(16, 3, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() #Summary helps view the layers in the model, and the number of parameters in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
    "\n",
    "- *Loss function:* This measures how accurate the model is during training. We want to minimize this function to \"steer\" the model in the right direction.\n",
    "- *Optimizer:* This decides the optimization technique used to achieve a minimum for the loss function\n",
    "- *Metrics:* Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified.\n",
    "- *Epochs:* These epochs represent the number of times the model will run through the training set, and affects how well the optimizer can converge to the best possible weights. Click [here](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9) to learn more about iterations, epochs and batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3) # Initialize an Adam optimizer with a learning rate of 0.001\n",
    "#Compile the model with the Adam optimizer and Categorical Cross Entropy loss\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['sparse_categorical_crossentropy'])\n",
    "EPOCHS = 100 #Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train the model. The `model.fit()` function takes in the Numpy data we obtained earlier. This function automatically handles backpropogation and updating model weights.\n",
    "\n",
    "To learn more about backpropagation and how neural networks learn, you can click [here](https://www.youtube.com/watch?v=aircAruvnKk) or [here](https://www.youtube.com/watch?v=Ilg3gGewQ5U)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainImages, trainLabels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can check some of the [weights](https://en.wikipedia.org/wiki/Synaptic_weight) from the trained neural network. These weights, in a way, represent the relationship between inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "weights[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Evaluate model training\n",
    "\n",
    "We use pyplot from [Matplotlib](https://matplotlib.org/) to plot the Learning Curve, which in the case of neural nets show shows the evolution of training and validation loss over epochs. In this simple example, our metric of accuracy is \"Sparse Categorical Crossentropy.\" Entropy in this context is a kind of information. It reflects ambiguity in a model by showing how much choice is permitted by the explanatory function. if there is Zero entropy, the model fully explains the features, so there is only one choice. if there is One entropy there are two equally viable choices. The entropy curve is logarithmic in nature.\n",
    "\n",
    "Here we only have a training set and no validation set. If we had used a validation set, we could have checked for overfitting by monitoring if validation crossentropy starts to raise while training entropy continues to fall. However, Keras, makes protecting against overfitting easy by exposing the `EarlyStopping()` functionality, click [here](https://keras.io/api/callbacks/early_stopping/) to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['sparse_categorical_crossentropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_accuracy, 'bo-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, if we are satisfied with the model training, we can check the accuracy of our model on our data. To do this, we will call the model.evaluate() function on the trainImages and trainLabels arrays. Accuracy can usually be improved by changing parameters in the building of the model, by running the training for more epochs and by feeding the model more instances of the training set (more images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(trainImages, trainLabels)\n",
    "test_loss, test_acc = model.evaluate(testImages, testLabels)\n",
    "\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a read-write filesystem we could, being satisfied at this point, save the model into an h5 format training by using the `model.save()` function. This saved model can be reloaded using the `load_model()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.save('./Models/classification_model.h5')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model = keras.models.load_model('./Models/classification_model.h5')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Make some predictions\n",
    "\n",
    "After these steps, we are ready to make predictions. This predictions represent the certainty the model has of each element belonging to a particular class.\n",
    "\n",
    "Predictions are made by calling the `model.predict()` function. The model will give a prediction for each of the elements on the testImages array.\n",
    "\n",
    "By calling `predictions[0]` we are accesing the array we created to store the model's predictions for element 0, the first image. We see that the model gives the maximum value of certainty to the category (label) \\#9, meaning that the model believes this image is an \"ankle boot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testImages)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Visualize results\n",
    "\n",
    "To visualize the predictions, we use two helper functions. The first function, `plot_image()`, generates an image from the set and presents the model's results in a color-coded fashion, displaying the prediction in RED if the prediction does not match the image and displaying the prediction in BLUE otherwise. The second function, `plot_value_array()` generates a bar chart representing the certainty of each of the classes for each element. This is also color-coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    prediction, gt_label, curr_img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "  \n",
    "    plt.imshow(curr_img, cmap='gray')\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    if predicted_label == gt_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "  \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label], 100*np.max(prediction), \n",
    "                                         class_names[int(gt_label)]), color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    prediction, gt_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(np.arange(10))\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), prediction, color=\"#777777\")\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    thisplot[int(predicted_label)].set_color('red')\n",
    "    thisplot[int(gt_label)].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(2,2,1)\n",
    "plot_image(i, predictions, testLabels, testImages)\n",
    "plt.subplot(2,2,2)\n",
    "plot_value_array(i, predictions,  testLabels)\n",
    "i = 12\n",
    "plt.subplot(2,2,3)\n",
    "plot_image(i, predictions, testLabels, testImages)\n",
    "plt.subplot(2,2,4)\n",
    "plot_value_array(i, predictions,  testLabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mrsicms)",
   "language": "python",
   "name": "mrsicms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
