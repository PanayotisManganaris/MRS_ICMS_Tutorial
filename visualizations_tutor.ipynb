{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Perovskite Dataset\n",
    "==============================\n",
    "\n",
    "**Author:** Panayotis Manganaris\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurization\n",
    "import cmcl\n",
    "from cmcl import Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "# transformations\n",
    "from sklearn.decomposition import PCA\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading stored targets and reference material\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = pd.read_csv(\"./mannodi_data.csv\").set_index([\"index\", \"Formula\", \"sim_cell\"])\n",
    "lookup = pd.read_csv(\"./constituent_properties.csv\").set_index(\"Formula\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cmcl provides an \"ft\" (feature) pandas DataFrame accessor. This\n",
    "accessor exposes batch feature extraction tools. The function ft.comp\n",
    "extracts composition vectors from the formula string in a dataframe\n",
    "(or dataframe index).\n",
    "\n",
    "The abx function of the collect accessor is a convenience function for\n",
    "grouping the resulting composition constituents by site membership\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = my.ft.comp() # compute numerical compostion vectors from strings\n",
    "mc = mc.collect.abx() # convenient site groupings for perovskites data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this can be used with the logif tool in categories to quickly\n",
    "categorize records by their mix status. that status is assigned to the\n",
    "index of the respective tables for further reference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixlog = mc.groupby(level=0, axis=1).count()\n",
    "mix = mixlog.pipe(Categories.logif, condition=lambda x: x>1, default=\"pure\", catstring=\"and\")\n",
    "mc = mc.assign(mix=mix).set_index(\"mix\", append=True)\n",
    "my = my.assign(mix=mix).set_index(\"mix\", append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derive_from function can be used to compute the site-averaged\n",
    "properties of each record.\n",
    "\n",
    "It performs a three-way N-to-N table join, performs a weighted\n",
    "averaging of any resulting redundant entries, and finally reshapes the\n",
    "results to be consistent with the outermost indices of the accessed\n",
    "data frame. Hence to obtain the site averaged properties, the\n",
    "composition table column labels must be grouped first, as above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = mc.ft.derive_from(lookup, \"element\", \"Formula\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target space\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main target of interest in this exercise is the Perovskite band\n",
    "gap.\n",
    "\n",
    "A number of properties including band gap and dielectric constant have\n",
    "been collected from DFT computations using the PBE functional.\n",
    "\n",
    "These properties are targets for modeling. Ideally, an empirical model\n",
    "can be found that fits to the underlying quantum mechanics, thereby\n",
    "acting as a surrogate for the DFT function in an active learning\n",
    "strategy which can quickly recommend compositions as high-performing\n",
    "candidates for DFT calculation.\n",
    "\n",
    "The target space is briefly summarized in both uni-variate and bi-variate views\n",
    "\n",
    "Note: there are an additional two \"SLME\" properties in the dataset\n",
    "(not shown here) that have extremely strong relations with band\n",
    "gap. They are computed using the band gap and a reference\n",
    "solar-absorption spectra. cmcl does not yet have a utility for\n",
    "computing them, so they are included in the sample data for reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "p = sns.pairplot(my.filter(regex=r\"PBE|dielc\").drop(\"PBE_dbg_eV\", axis=1).assign(mix=mix), hue='mix')\n",
    "p.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature space\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition Distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "composition vectors are a set of primary descriptors for the\n",
    "Perovskites being examined &#x2013; most other meaningful features are at\n",
    "least partially derived from them. Another primary descriptor is the\n",
    "crystal structure. For now, it is understood that the 496 records\n",
    "being examined are all cubic perovskites (within a tolerance). They\n",
    "differ firstly in composition and secondly in alloy character. Alloy\n",
    "character as a metric is completely encapsulated in the composition\n",
    "vectors, but nonetheless represents an important consideration in\n",
    "ensuring the model's generality.\n",
    "\n",
    "It will be a goal of modeling to create regressions that will be able\n",
    "to extrapolate targets between the existing alloy character classes.\n",
    "(AandBandX-site alloys).\n",
    "\n",
    "Here, uni-variate distributions over finite bounds on composition\n",
    "ratios are explored with respect to the alloy class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmc = pd.DataFrame(\n",
    "        mc.fillna(0).pipe(Normalizer(norm=\"l1\").fit_transform), #normalizing the data by each vector's manhattan length gives proportional quantities\n",
    "        columns=mc.columns,\n",
    "        index=mc.index).assign(mix=mix)\n",
    "\n",
    "nmc = pd.melt(pmc, id_vars=\"mix\").replace(0, np.NaN).dropna() # eliminate the \"zeros\" (missing values) to focus on the meaningful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"poster\"):\n",
    "    p = sns.catplot(x=\"value\", col=\"element\", data=nmc, col_wrap=5, kind=\"count\", hue=\"mix\",\n",
    "                    col_order=[\"Ba\", \"Ge\", \"Cl\", \"Br\", \"I\", \"Sn\", \"Pb\", \"Cs\", \"FA\", \"MA\", \"Sr\", \"Ca\", \"Rb\", \"K\"])\n",
    "    (p.set_xticklabels(rotation=90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site-Averaged Properties Distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxr = pd.IndexSlice\n",
    "some_axes = mp.loc[:, dxr[:, mp.columns.get_level_values(1)[0:4]]] #change these level value slices to focus on different site axes or remove slicing to see all\n",
    "\n",
    "pmp = pd.DataFrame(\n",
    "        some_axes.pipe(StandardScaler().fit_transform), #Z transform scales dimensions so they are comparable\n",
    "        columns=some_axes.columns,\n",
    "        index=some_axes.index).assign(mix=mix)\n",
    "\n",
    "smp = pd.melt(pmp, id_vars=\"mix\").replace(0, np.NaN).dropna() # eliminate \"zeros\" (missing values) to focus on the meaningful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\"):\n",
    "    p = sns.displot(x=\"value\", col=smp.iloc[:,2], row=\"site\", data=smp, kind=\"hist\", hue=\"mix\", multiple='stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-variate relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is unlikely that any of the targets is full explained by a single\n",
    "composition or composition derived axis. But there are probably\n",
    "relations.\n",
    "\n",
    "A Pearson correlation map will be produced to check for strong\n",
    "relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### targets vs composition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_v_targets = pd.concat([my, pmc], axis=1).select_dtypes(np.number).fillna(0)\n",
    "pearson = pd.DataFrame(np.corrcoef(mc_v_targets, rowvar=False),\n",
    "                       columns=mc_v_targets.columns,\n",
    "                       index=mc_v_targets.columns)\n",
    "subset = pearson.filter(regex=r\"PBE|dielc|SLME\", axis=0).filter(regex=r\"^(?!PBE|HSE|SLME|dielc|PV_FOM)\")\n",
    "#first filter picks targets, second selects bases\n",
    "p = sns.heatmap(subset, vmax=1.0, vmin=-1.0, cmap=\"seismic\")\n",
    "p.set_xticklabels(p.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "p.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### targets vs site-averaged properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_v_targets = pd.concat([my, pmp], axis=1).select_dtypes(np.number).fillna(0)\n",
    "pearson = pd.DataFrame(np.corrcoef(mp_v_targets, rowvar=False),\n",
    "                       columns=mp_v_targets.columns,\n",
    "                       index=mp_v_targets.columns)\n",
    "subset = pearson.filter(regex=r\"PBE|dielc|SLME\", axis=0).filter(regex=r\"^(?!PBE|HSE|SLME|dielc|PV_FOM)\")\n",
    "#first filter picks targets, second selects bases\n",
    "p = sns.heatmap(subset, vmax=1.0, vmin=-1.0, cmap=\"seismic\")\n",
    "p.set_xticklabels(p.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "p.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to plot any interesting looking correlations in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=(\"X\",\"dens_g/cc\"), y=\"PBE_bg_eV\", data=mp_v_targets, hue=\"mix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better idea of what structures statistical models might be able to find in the\n",
    "complete dataset, the structure and effects of many variables at a time must be inspected.\n",
    "\n",
    "Principal Component Analysis is a method of projecting high dimensional data onto a plane defined by the two linear combinations of axes that explain as much of the variance as possible.\n",
    "\n",
    "The method of PCA is the Singular Value Decomposition, a Unitary Transform which generalizes the familiar eigendecomposition.\n",
    "Essentially, that means PCA will \"rotate\" the n data points in m-D space until you can see them at their widest in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biplot(choose, PCs, transform_matrix):\n",
    "    #a much better and more user friendly version of this function will be available in a future version of spyglass. stay tuned.\n",
    "    ax = plt.gca()\n",
    "    n = transform_matrix.shape[0]\n",
    "    xs = PCs.iloc[:,choose[0]]\n",
    "    ys = PCs.iloc[:,choose[1]]\n",
    "    scalex = 1.0/(xs.max() - xs.min())\n",
    "    scaley = 1.0/(ys.max() - ys.min())\n",
    "    scatterplane = ax.scatter(xs * scalex, ys * scaley, c = 'k')\n",
    "    slice1 = transform_matrix[choose[0]]\n",
    "    slice2 = transform_matrix[choose[1]]\n",
    "    proj_slice_transposed = np.stack([slice1, slice2], axis=1)\n",
    "    xs_weight = proj_slice_transposed[:,0]\n",
    "    ys_weight = proj_slice_transposed[:,1]\n",
    "    for i in range(n):\n",
    "        ax.arrow(0, 0, xs_weight[i], ys_weight[i], color = 'r', alpha = 0.5)\n",
    "        ax.text(xs_weight[i] * 1.2, ys_weight[i] * 1.2, df.columns[i], color = 'g', ha = 'center', va = 'center')\n",
    "    ax.set_xlabel(\"PC{}\".format(choose[0]))\n",
    "    ax.set_ylabel(\"PC{}\".format(choose[1]))\n",
    "    ax.grid()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pmc.select_dtypes(np.number) #change out pmc for other dataframes created above to explore how various dimensions contribute to the data space.\n",
    "\n",
    "pcaxis = PCA(n_components = min(df.shape), svd_solver = 'full') #pca can be truncated for speed, but with these dimensions it is not necessary.\n",
    "pcadf = pd.DataFrame(pcaxis.fit_transform(df), index=df.index, columns=['pc_%i' % i for i in range(pcaxis.n_components)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = biplot(choose=[0,1], PCs=pcadf, transform_matrix=pcaxis.components_)\n",
    "#change the two numbers in the choose list to view other principal components orthogonal to the first two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it is readily apparent that this dataset is highly topological. The data exists on a mostly bounded domain in high dimensions, so there is some geometry the features constitute.\n",
    "\n",
    "Our models will prefer to use this this geometric structure in their explaination for why perovskite properties vary, this can be useful for accuracy, it can also be a bias-inducing hinderance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mrsicms)",
   "language": "python",
   "name": "mrsicms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
