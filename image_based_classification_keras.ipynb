{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Using neural networks to recognize clothing items from their images*\n",
    " \n",
    " \n",
    "In this tutorial, we will train a neural network on the [Fashion MNIST Dataset](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) and classify various images into different types of clothing items. \n",
    "\n",
    "A general outline for this tutorial would be as follows:\n",
    "\n",
    "1. Import libraries\n",
    "2. Import the Fashion MNIST dataset \n",
    "3. Explore and preprocess the data\n",
    "4. Build and train a neural network to model the data\n",
    "5. Evaluate model accuracy\n",
    "6. Make some predictions\n",
    "7. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Import libraries\n",
    "\n",
    "We first import the relevant libraries. This includes Tensorflow and [Keras](https://www.tensorflow.org/guide/keras) to build and train neural networks, [Numpy](https://docs.scipy.org/doc/numpy-1.15.1/user/index.html) to process the data, and pyplot from [Matplotlib](https://matplotlib.org/) for plotting. We will also use the [Gzip](https://docs.python.org/3/library/gzip.html) and os libraries to handle zipped (compressed) files and to place the extracted data in the correct directories. The [subprocess](https://docs.python.org/2/library/subprocess.html) library allows us to call Unix shell commands from a Python script, and will be used to get the data from an online server directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from subprocess import call\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Import the Fashion MNIST dataset\n",
    "\n",
    "\n",
    "The Fashion MNIST database contains 70,000 grayscale images of 10 different categories of clothing items. The images show individual articles of clothing at low resolution (28 by 28 pixels). We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images.\n",
    "\n",
    "For more information on the dataset, click [here](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/).\n",
    "\n",
    "Testing and training datasets are located as compressed in gzip files [here](https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz). To download the data from this location, we define two helper functions. The first is `load_data()`, which uses the subprocess library to call the `wget` Unix command that downloads data from an online location to a specified directory on our system. This directory is specificed using the os library. The second function `extract_data()`, takes the data from the gzip and formats it into a (60,000 x 28 x 28 x 1) array of 8 byte, unsigned integers. In this notation, 60,000 is the number of training images, 28 is the height and width of each image (in pixels), and 1 is the number of \"channels\" in the image. For a grayscale image, the number of \"channels\" is 1, a colored image would have 3 \"channels\" (RGB).\n",
    "\n",
    "Labels for each image are defined as a number from 0 to 9, each corresponding to a class of clothing items, these class labels are defined in a list.\n",
    "\n",
    "Label | Class\n",
    "--- | --- \n",
    "0 | Tshirt/top\n",
    "1 | Trouser\n",
    "2 | Pullover\n",
    "3 | Dress\n",
    "4 | Coat\n",
    "5 | Sandal\n",
    "6 | Shirt\n",
    "7 | Sneaker\n",
    "8 | Bag\n",
    "9 | Ankle Boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_data, head_size, data_size): # This function loads and parses the data\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(head_size)\n",
    "        buf = bytestream.read(data_size * num_data)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8)\n",
    "    return data\n",
    "\n",
    "def load_data():\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz  -o \" \\\n",
    "         + os.getcwd() + \"t10k-images-idx3-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz -o \" \\\n",
    "         + os.getcwd() + \"train-images-idx3-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz -o \" \\\n",
    "         + os.getcwd() + \"train-labels-idx1-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz -o \" \\\n",
    "         + os.getcwd() + \"t10k-labels-idx1-ubyte.gz\", shell=True)\n",
    "\n",
    "    trainImages = extract_data(os.getcwd() + '/train-images-idx3-ubyte.gz', 60000, 16, 28*28)\n",
    "    testImages = extract_data(os.getcwd()  + '/t10k-images-idx3-ubyte.gz', 10000, 16, 28*28)\n",
    "    \n",
    "    trainLabels = extract_data(os.getcwd() + '/train-labels-idx1-ubyte.gz', 60000, 8, 1)\n",
    "    testLabels = extract_data(os.getcwd()  + '/t10k-labels-idx1-ubyte.gz', 10000, 8, 1)\n",
    "    \n",
    "    trainImages = trainImages.reshape((60000, 28, 28, 1))\n",
    "    testImages = testImages.reshape((10000, 28, 28, 1))\n",
    "    \n",
    "    trainLabels = trainLabels.reshape((60000, 1))\n",
    "    testLabels = testLabels.reshape((10000, 1))\n",
    "    \n",
    "    return trainImages, testImages, trainLabels, testLabels\n",
    "\n",
    "\n",
    "trainImages, testImages, trainLabels, testLabels = load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', \n",
    "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # Label Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Explore and preprocess the data\n",
    "\n",
    "To ensure that data was loaded correctly, we will now look at a sample image from the training set.\n",
    "\n",
    "- You can modify the variable **\"index\"** in the following code to get any image in the training set\n",
    "- You can print the shapes of all arrays being used to check whether the data was loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "index = 0 #index runs from 0 to 59999\n",
    "plt.imshow(trainImages[index], cmap='gray') # By altering 'index' you will see another of the pictures imported\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "\n",
    "print(\"Train Images Array shape:\", trainImages.shape)\n",
    "print(\"Train Labels Array shape:\", trainLabels.shape)\n",
    "print(\"Test Images Array shape:\", testImages.shape)\n",
    "print(\"Test Labels Array shape:\", testLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now scale the data to range between 0 and 1 before feeding it to the neural network model. It's important that the training set and the testing set are preprocessed in the same way and we thus divide the training and testing data by 255 (the maximum value that can be possibly achieved). Click [here](https://en.wikipedia.org/wiki/Feature_scaling) to learn about other types for feature (input) scaling.\n",
    "\n",
    "After this, we display the first 25 images from the dataset to visualize the variety of images in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = trainImages/255.0\n",
    "testImages = testImages/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainImages[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[int(trainLabels[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Build and train neural network to model the data\n",
    "\n",
    "Building the neural network requires configuring the layers of the model, then compiling the model. Once again, we use the Sequential class to quickly add layers to our model.\n",
    "\n",
    "In this instance, we will be using the `Conv2D` layers that represent convolution operations on an input array. These convolution operations use \"filters\" to learn the features in the images. These \"filters\" are small matrices (often 2x2 or 3x3) whose entries are learnt by the model during training. These values are optimized such that the network learns image features across multiple `Conv2D` layers. Another layer we will be using is the `Pool` layer, which \"pools\" or gathers information from a set of pixels into one pixel. To learn more about `Conv2D` layers and the underlying operations, click [here](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks).\n",
    "\n",
    "After multiple convolution and pooling operations, we will use a `Flatten` layer to flatten the image into a long vector of numbers. Finally, we will use a `Dense` layer to predict the output of the network, which will be a set of 10 numbers that each define the probability of the current image being of that image class.\n",
    "\n",
    "The convolutional layers use a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks) (Rectified Linear Unit) [activation function](https://en.wikipedia.org/wiki/Activation_function), which can be seen as a \"ramp\" function in which only the positive part of the input passes through.\n",
    "\n",
    "The output layer layer uses a **SoftMax** (Normalized Exponential Function) activation, in which inputs are mapped into real values such that each value is between 0 and 1 and the sum of all values equals one. This helps us interpret these outputs as probabilities, and further distill them as predicted classes\n",
    "\n",
    "Click [here](https://towardsdatascience.com/secret-sauce-behind-the-beauty-of-deep-learning-beginners-guide-to-activation-functions-a8e23a57d046) to see and visualize the equations describing these activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(28, 28, 1)))\n",
    "model.add(layers.Conv2D(8, 3, activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(16, 3, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() #Summary helps view the layers in the model, and the number of parameters in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
    "\n",
    "- *Loss function:* This measures how accurate the model is during training. We want to minimize this function to \"steer\" the model in the right direction.\n",
    "- *Optimizer:* This decides the optimization technique used to achieve a minimum for the loss function\n",
    "- *Metrics:* Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified.\n",
    "- *Epochs:* These epochs represent the number of times the model will run through the training set, and affects how well the optimizer can converge to the best possible weights. Click [here](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9) to learn more about iterations, epochs and batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3) # Initialize an Adam optimizer with a learning rate of 0.001\n",
    "#Compile the model with the Adam optimizer and Categorical Cross Entropy loss\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "EPOCHS = 100 #Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Train the model\n",
    "\n",
    "The `model.fit()` function is used to train the model we just created, the inputs for this function being the training set and the defined number of epochs.\n",
    "To learn more about how neural networks learn, you can click [here](https://www.youtube.com/watch?v=aircAruvnKk) or [here](https://www.youtube.com/watch?v=Ilg3gGewQ5U)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainImages, trainLabels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_accuracy, 'bo-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can check some of the [weights](https://en.wikipedia.org/wiki/Synaptic_weight) from the trained neural network. These weights, in a way, represent the relationship between inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Models/classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = keras.models.load_model('./Models/classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Evaluate model accuracy\n",
    "\n",
    "Accuracy is the way we can evaluate how well a particular model is being fit to a particular training data set. By calling the function `model.evaluate()` on the trainImages and trainLabels arrays, we can check the accuray of our model on the training images.\n",
    "\n",
    "For the default values on this tutorial, we get around *90%* accuracy on the training set and *88%* accuracy on the testing set. Accuracy can usually be improved by changing parameters in the building of the model, by running the training for more epochs and by feeding the model more instances of the training set (more images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(trainImages, trainLabels)\n",
    "test_loss, test_acc = model.evaluate(testImages, testLabels)\n",
    "\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Make some predictions\n",
    "\n",
    "After these steps, we are ready to make predictions. This predictions represent the certainty the model has of each element belonging to a particular class.\n",
    "\n",
    "Predictions are made by calling the `model.predict()` function. The model will give a prediction for each of the elements on the testImages array.\n",
    "\n",
    "By calling `predictions[0]` we are accesing the array we created to store the model's predictions for element 0, the first image. We see that the model gives the maximum value of certainty to the category (label) \\#9, meaning that the model believes this image is an \"ankle boot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testImages)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Visualize results\n",
    "\n",
    "To visualize the predictions, we use two helper functions. The first function, `plot_image()`, generates an image from the set and presents the model's results in a color-coded fashion, displaying the prediction in RED if the prediction does not match the image and displaying the prediction in BLUE otherwise. The second function, `plot_value_array()` generates a bar chart representing the certainty of each of the classes for each element. This is also color-coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    prediction, gt_label, curr_img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "  \n",
    "    plt.imshow(curr_img, cmap='gray')\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    if predicted_label == gt_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "  \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label], 100*np.max(prediction), \n",
    "                                         class_names[int(gt_label)]), color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    prediction, gt_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(np.arange(10))\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), prediction, color=\"#777777\")\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    \n",
    "    thisplot[int(predicted_label)].set_color('red')\n",
    "    thisplot[int(gt_label)].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(2,2,1)\n",
    "plot_image(i, predictions, testLabels, testImages)\n",
    "plt.subplot(2,2,2)\n",
    "plot_value_array(i, predictions,  testLabels)\n",
    "i = 12\n",
    "plt.subplot(2,2,3)\n",
    "plot_image(i, predictions, testLabels, testImages)\n",
    "plt.subplot(2,2,4)\n",
    "plot_value_array(i, predictions,  testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mrsicms)",
   "language": "python",
   "name": "mrsicms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
